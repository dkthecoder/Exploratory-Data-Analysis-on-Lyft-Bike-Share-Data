# -*- coding: utf-8 -*-
"""EDA_assignment_rev3-final_(colab)

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1dt_czoLEqYxIoCA-v7Ynu0XHCWHnFWsB
"""

#import of libraries
import pandas as pd
import glob
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

"""---
# Exploratory Data Analysis on Lyft Bike-Share Data

For this project I am using the Lyft bike sharing trips data collected between Jan 2019 and May 2019 from the Bay Area (California). This data has been taken from Kaggle and is available at; https://www.kaggle.com/jolasa/bay-area-bike-sharing-trips

Let's begin by importing our data into pandas. This notebook assumes you're using Google Colab. Be sure to adust the "path" directory to the folder of CSV files.
"""

#path must point to the folder with .CSV files.
path = r'/content/data' # use your path
all_files = glob.glob(path + "/*.csv")

li = []

for filename in all_files:
    df = pd.read_csv(filename, index_col=None, header=0)
    li.append(df)

#big frame with all csv data from Jan to May.
data = pd.concat(li, axis=0, ignore_index=True)
data.head()

data.shape

"""There are 10 columns with over a million data entries. each collumn reffers to month, trip duration (seconds), start station id, start station name, end station id, endstation name, bike ID, user type, member  DOB and member genger. For several attributes such as Education, each datapoint is a representative for description as follows:

Month
1.   January
2.   February
3.   March
4.   April
5.   May

User Type
1.   Customer
2.   Subscriber

Member Gender
1.   Male
2.   Female

---
# Data Cleaning

Before we explore our data, lets clean up any missing values by deleting them. Due to the number of entries, deleting rows with missing attributes should not have a drastic affect on the exploration of the data later.
"""

#Count missing values in each column.
data.isna().sum()

#drop any rows with missing values
data = data.dropna(axis=0, how='any', thresh=None, subset=None, inplace=False)

#check if we have any missing attributes in any rows.
#True = rows with missing attributes.
#False = everything is populated.
data.isnull().values.any()

data.info()

"""When we check what data types we're working with, some of the columns are of the incorrect type. For example, "start_station_id", "end_station_id" and "member_birth_year" are "float64" while they really should be "int64". Let's change this."""

#Change the following fields to an appropriate data type.
data = data.astype({'start_station_id': np.int64})
data = data.astype({'end_station_id': np.int64})
data = data.astype({'member_birth_year': np.int64})

data.shape

"""Once the null values have been removed, we shall take a look at the descriptive statistics  in the dataset below. As from the above code, the shape of the dataframe has not drastically changes, we still have over a million data entries to explore."""

#Print all of the object data types and their unique values
for column in data.columns:
    if data[column].dtype == object:
        print(str(column) + ' : ' + str(data[column].unique()))
        print(data[column].value_counts())
        print("_________________________________________________________________")

"""---
# Data Visualisation

Let's start exploring our data, it may be best to see what collumns may correlate to what. Though this may not make much sense, since some the data isnt numerical, and some of the values repeat (such as bike_id). But lets do it anyway and see what shows.

"""

data_corr = data.corr()
data_corr
plt.figure(figsize=(8,6))
sns.set_context('paper')

sns.heatmap(data_corr, annot=True, cmap='Blues', fmt='.0%')

#broad look at data distribution
sns.pairplot(data)

#count plot of members DOB
fig_dims = (18, 6)
fig, ax = plt.subplots(figsize=fig_dims)

#ax = axis
plt.xticks(rotation=90)
sns.countplot(x='member_birth_year', hue='member_gender', data=data, ax = ax)

#count plot with hue
fig_dims = (18, 6)
fig, ax = plt.subplots(figsize=fig_dims)

#ax = axis
plt.xticks(rotation=90)
sns.countplot(x='member_birth_year', hue='user_type', data = data, ax = ax);

"""The above two graphs show the count of DOB, plotted with their gender and their user type. There seems to be a skew that leans to the left in both cases. Though, I feel it is important to note that there is no way to know the unique count of age to determine unique number of users. Though, this representation can give an idea of which age demogrpahic the bike share is most popular with."""

fig_dims = (12, 3)
#average trip duration by member birth year
data.groupby(['member_birth_year']).mean().pipe(lambda data: sns.relplot(data=data, x="member_birth_year", y="trip_duration_sec", kind="scatter"))

"""We can see when we plot member_birth_year with average trip duration the average duration of their trip against age.

There seems to be values far below the correlation of the data which suggests possible anomolies in the data regarding member_birth_year.
"""

#station popularity
allstations = pd.DataFrame(columns=["Stations"]) # creating new dataframe
allstations = pd.concat([data['start_station_id'], data['end_station_id']])# "concating" the two columns

uniqueid = np.unique(allstations) # Returning all the unique values from the allstation dataframe that we created earlier.
stationsusage = pd.DataFrame(columns=["station_id","Total_Uses"]) # new dataframe
for row in uniqueid:
    temp1 = data[data.start_station_id == row]# As start station
    temp2 = data[data.end_station_id == row] # As end station
    tempsum = len(temp1)+len(temp2) # sum
    stationsusage = stationsusage.append({'station_id':row,'Total_Uses':tempsum}, ignore_index=True) # add row on our dataframe

#plot graph
fig_dims = (40, 8)
fig, ax = plt.subplots(figsize=fig_dims)
#ax = axis
plt.xticks(rotation=90)
sns.barplot(data=stationsusage, x='station_id', y='Total_Uses')

"""The above graph shows the total uses of a bike station, per its bike ID. I had attempted to plot this with the bike station name but the x axis was illegable. We can see some station have more popularity than others. Specifically double-digit station ID's which where possible placed in key areas with a high flow of people."""

#box plot gender, unique users and member age
sns.stripplot(x='month', y='bike_id', data=data, hue='member_gender' )
plt.legend(loc=0)

#the members age and trip duration
sns.jointplot(x='member_birth_year', y='trip_duration_sec', data=data)

#count of user_type with split into member_gender
sns.countplot(data=data, x='user_type', hue='member_gender')

"""The above chart represents the type of user and the count of how many times a user has used the service in the given 5 month period.

---


# Hypothesis Formulation

From the above graphs, we got some insight about the data. Since this data can be used to make a prediciton based on age group of the user, and if they are a customer or subscriber to understand how much they are likely to use the service and to what capacity, we have to know the attributes that has positive or negative and strong or weak correlation with usage. Here I made several hypotheses regarding to this matter.


First hypothesis

**H0** = The younger the user, the more likely they are going to use the service.

**Ha** = The older the user, the more likely they are going to use the service.

Second hypothesis

**H0** = The younger the member, the longer they will use the service.

**Ha** = The older the member, the longer they will use the service.

Third hypothesis

**H0** = Popular stations are more likely to be used by subscribers.

**Ha** = Popular stations are less likely to be used by subscribers.

---
#Hypothesis Testing & Result

To test the hypothesis, I made a new chart bellow consisting of member_gender attribute, plotted to a historgram. If the hypothesis is true, we should see a left-skewed regression line. Else, if false, a right-skewed regression line. For extra exploration I have added the gender attribute as well.
"""

#histogram of age

#plot graph
fig_dims = (8, 8)
fig, ax = plt.subplots(figsize=fig_dims)

sns.histplot(data=data, x="member_birth_year", kde=True, hue="member_gender")

"""As shown above, the majority concesos of users lay around the "1990" area of the chart... While the regression line drops sharply off with anyone younger than 1995, or for anyone who may be older than 1990.

Further to this, we can see the majority of users are mail, however, there regression line is flatter for females as opposed to males. This may indicate that there is a higher likelyhood that the bike-sharing service appeals to a broader age demogaphic for woman than for men.

---
# Summary

For further analysis, I suggest that we can do more insight finding in each variable through feature engineering, for example, reating unique counts of bikes at locations to understand how many times a location may be used. Further to this, involving other data sources such as map data to understand popularity distribution of the bikes and map out rough travel through the trip_duration_sec attribute. Thus, estimating the type of journey a bike may make.

There are some items missing from the dataset that could've been useful, such as time & date, distanc travelled by each bike or even a recalcualted ID per each user, to document multiple uses by the same member, thus understanding customer behaviour.
"""